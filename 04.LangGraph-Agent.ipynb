{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec680f5",
   "metadata": {},
   "source": [
    "# LangGraph 활용 Agent 구축\n",
    "\n",
    "학습 목표 \n",
    "- LangGraph에 웹 검색 도구 + LLM Agent 추가 \n",
    "- LLM 에 도구를 바인딩 -> LLM 에 입력된 요청에 따라 필요시 웹 검색 도구(Tool)를 호출하는 Agent 을 구축\n",
    "- 조건부 엣지를 통해 도구 호출 여부에 따라 다른 노드로 라우팅하는 방법 배우기 \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e063a2",
   "metadata": {},
   "source": [
    "## Agent를 LangGraph와 함께 사용하는 것에 대한 장점\n",
    "\n",
    "Agent만 단독으로 사용하는 경우 컨트롤이 어렵다. \n",
    "- 예를들어, 문서 검색 도구와 웹 검색 도구 2가지 도구가 바인딩 된 Agent를 사용한다고 가정하자.  \n",
    "- 문서 검색 도구를 사용해서 내가 보유한 문서를 우선적으로 검색하여 답변을 생성하기를 원하지만, 웹 검색을 해서 적절한 답변 생성을 수행하지 못하는 경우가 있다. \n",
    "- 단대로 웹 검색을 해야하는데 문서 검색을 해서 필요 없는 정보들을 제공할 수 있다. \n",
    "\n",
    "Agent를 LangGraph와 결합할 경우 컨트롤에 용이하다.\n",
    "- Agent가 사용한 도구를 선정할 때, LangGraph의 노드들이 이를 확인해줄 수 있다. \n",
    "- 또는 LangGraph에 Human-in-the-loop 이 있기 때문에 사람의 개입을 통해 Agent가 적절한 도구를 사용하게 할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5376bf",
   "metadata": {},
   "source": [
    "## 도구(Tool) 사용하기\n",
    "\n",
    "- pre-trained llm이 답변할 수 없는 질문을 처리하기 위해 `웹 검색 도구`를 통합\n",
    "- 도구를 사용하여 더 나은 응답을 제공\n",
    "\n",
    "**참고**\n",
    "\n",
    "- [도구(Tools)](https://wikidocs.net/262582)\n",
    "\n",
    "\n",
    "### 검색 API 도구\n",
    "\n",
    "웹 검색 도구 : Tavily 검색 API를 활용\n",
    "- `TavilySearchResults`와 `TavilyAnswer`.\n",
    "\n",
    "\n",
    "**API 키 발급 주소**\n",
    "- https://app.tavily.com/\n",
    "\n",
    "발급한 API 키를 환경변수에 설정\n",
    "\n",
    "- `.env` 파일에 아래와 같이 설정\n",
    "\n",
    "```\n",
    "TAVILY_API_KEY=tvly-abcdefghijklmnopqrstuvwxyz\n",
    "```\n",
    "\n",
    "### TavilySearchResults\n",
    "\n",
    "**설명**\n",
    "- Tavily 검색 API를 쿼리하고 JSON 형식의 결과를 반환\n",
    "- 포괄적이고 정확하며 신뢰할 수 있는 결과에 최적화된 검색 엔진"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cbcea8",
   "metadata": {},
   "source": [
    "다음으로 웹 검색 도구인 `TavilySearchResults`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163da255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U langchain-teddynote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a827284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API 키를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API 키 정보 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04fccdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': '랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-01/', 'content': \"랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) 튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다. ada-code-search-text code-search-ada-text-001 result = llm_chain.apply(input_list) generated_result = llm_chain.generate(input_list) generations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))] [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] result = llm_chain.apply(input_list) 태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 랭체인, 랭체인 튜토리얼\", 'score': 0.80070794, 'raw_content': \"랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 (1)\\n2023년 09월 28일 5 분 소요\\n목차\\n\\n🌱 랭체인의 주요 기능\\n🌱 환경설정\\nAPI KEY 발급\\n모듈 설치(openai, langchain)\\n\\n\\n🔥 ChatOpenAI\\n🔥 프롬프트 템플릿의 활용\\nLLMChain 객체\\n① run()\\n② apply()\\n③ generate()\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n⑤ 스트리밍(streaming)\\n\\n\\n\\n언어 모델을 활용한 애플리케이션 개발을 돕는 프레임워크인 랭체인(LangChain) 에 대해 깊이 있게 다뤄보고자 합니다.\\n튜토리얼은 시리즈 형식으로 구성되어, 시리즈를 거듭하면서 랭체인(LangChain) 을 통해 언어 모델 기반의 애플리케이션 개발은 더욱 간결하고 효과적으로 이루어질 수 있습니다.\\n🌱 랭체인의 주요 기능\\n랭체인을 통해 다음과 같은 특징을 갖는 애플리케이션을 개발할 수 있습니다.\\n\\n문맥 인식: 언어 모델과 다양한 문맥 소스(프롬프트 지시, 예제, 응답의 근거 내용 등)를 연동하며, 사용자의 문맥을 정확히 이해합니다.\\n추론 능력: 제공된 문맥에 기반하여 어떤 대답을 할지, 또는 어떠한 액션을 취할지에 대한 추론이 가능합니다.\\n\\n랭체인의 가치\\n랭체인의 핵심적인 가치는 여러 가지가 있지만, 그 중에서도 두 가지 주요한 점을 꼽자면 다음과 같습니다.\\n\\n구성 요소: 사용자는 언어 모델과의 상호작용을 위해 다양한 구성 요소와 추상화를 활용할 수 있습니다. 이러한 구성 요소는 개별적으로, 또는 랭체인 프레임워크 내에서 모듈식으로 쉽게 활용할 수 있습니다.\\n사용 준비된 체인: 특정 고수준 작업을 수행하기 위해 미리 조립된 구성 요소의 패키지입니다.\\n\\n특히, 이러한 사용 준비된 체인은 초보자도 랭체인을 쉽게 시작할 수 있게 도와주며, 복잡한 애플리케이션을 계획하는 전문가들은 기존 체인을 손쉽게 커스터마이징하거나 새롭게 구축할 수 있게 도와줍니다.\\n🌱 환경설정\\nAPI KEY 발급\\n먼저, openai 의 API KEY 를 발급 받아야 합니다. 발급은 다음의 절차를 통해 진행할 수 있습니다.\\nhttps://platform.openai.com/account/api-keys 로 접속합니다.\\n\\nLog in 버튼을 클릭 후 계정에 로그인 합니다. 계정이 아직 생성되지 않은 경우에는 Sign up 으로 회원가입 후 로그인 합니다.\\n\\n\\n\\n“Create new secret key” 버튼을 클릭하여 새로운 키를 발급합니다.\\n\\n\\n\\nName 에는 발급하는 키에 대한 별칭을 입력합니다.\\n\\n\\n\\n새롭게 발급한 키를 복사합니다. 잃어버리면 다시 발급하여야 하므로, 안전한 곳에 저장해 둡니다.\\n\\n\\n모듈 설치(openai, langchain)\\npip 명령어로 모듈을 설치 합니다. 아나콘다 가상환경에서 설치해도 좋습니다.\\n```\\nopenai 파이썬 패키지 설치\\npip install openai langchain\\n```\\n먼저, 설치한 openai 모듈을 import 한 뒤, 발급받은 API KEY를 다음과 같이 설정합니다.\\n```\\nimport os\\nos.environ['OPENAI_API_KEY'] = 'OPENAI API KEY 입력'\\n```\\n사용 가능한 모델 리스트 출력\\n```\\nimport openai\\nmodel_list = sorted([m['id'] for m in openai.Model.list()['data']])\\nfor m in model_list:\\n    print(m)\\n```\\nada\\nada-code-search-code\\nada-code-search-text\\nada-search-document\\nada-search-query\\nada-similarity\\nbabbage\\nbabbage-002\\nbabbage-code-search-code\\nbabbage-code-search-text\\nbabbage-search-document\\nbabbage-search-query\\nbabbage-similarity\\ncode-davinci-edit-001\\ncode-search-ada-code-001\\ncode-search-ada-text-001\\ncode-search-babbage-code-001\\ncode-search-babbage-text-001\\ncurie\\ncurie-instruct-beta\\ncurie-search-document\\ncurie-search-query\\ncurie-similarity\\ndavinci\\ndavinci-002\\ndavinci-instruct-beta\\ndavinci-search-document\\ndavinci-search-query\\ndavinci-similarity\\ngpt-3.5-turbo\\ngpt-3.5-turbo-0301\\ngpt-3.5-turbo-0613\\ngpt-3.5-turbo-16k\\ngpt-3.5-turbo-16k-0613\\ngpt-3.5-turbo-instruct\\ngpt-3.5-turbo-instruct-0914\\ngpt-4\\ngpt-4-0314\\ngpt-4-0613\\ntext-ada-001\\ntext-babbage-001\\ntext-curie-001\\ntext-davinci-001\\ntext-davinci-002\\ntext-davinci-003\\ntext-davinci-edit-001\\ntext-embedding-ada-002\\ntext-search-ada-doc-001\\ntext-search-ada-query-001\\ntext-search-babbage-doc-001\\ntext-search-babbage-query-001\\ntext-search-curie-doc-001\\ntext-search-curie-query-001\\ntext-search-davinci-doc-001\\ntext-search-davinci-query-001\\ntext-similarity-ada-001\\ntext-similarity-babbage-001\\ntext-similarity-curie-001\\ntext-similarity-davinci-001\\nwhisper-1\\n🔥 ChatOpenAI\\nOpenAI 사의 채팅 전용 Large Language Model(llm) 입니다.\\n객체를 생성할 때 다음을 옵션 값을 지정할 수 있습니다. 옵션에 대한 상세 설명은 다음과 같습니다.\\ntemperature\\n\\n사용할 샘플링 온도는 0과 2 사이에서 선택합니다. 0.8과 같은 높은 값은 출력을 더 무작위하게 만들고, 0.2와 같은 낮은 값은 출력을 더 집중되고 결정론적으로 만듭니다.\\n\\nmax_tokens\\n\\n채팅 완성에서 생성할 토큰의 최대 개수입니다.\\n\\nmodel_name: 적용 가능한 모델 리스트\\n\\n\\ngpt-3.5-turbo\\n\\n\\ngpt-3.5-turbo-0301\\n\\n\\ngpt-3.5-turbo-0613\\n\\n\\ngpt-3.5-turbo-16k\\n\\n\\ngpt-3.5-turbo-16k-0613\\n\\n\\ngpt-3.5-turbo-instruct\\n\\n\\ngpt-3.5-turbo-instruct-0914\\n\\n\\ngpt-4\\n\\n\\ngpt-4-0314\\n\\n\\ngpt-4-0613\\n\\n\\n```\\nfrom langchain.chat_models import ChatOpenAI\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                )\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n질의\\nprint(f'[답변]: {llm.predict(question)}')\\n```\\n[답변]: 대한민국의 수도는 서울입니다.\\n🔥 프롬프트 템플릿의 활용\\nPromptTemplate\\n\\n\\n사용자의 입력 변수를 사용하여 완전한 프롬프트 문자열을 만드는 데 사용되는 템플릿입니다\\n\\n\\n사용법\\n\\n\\ntemplate: 템플릿 문자열입니다. 이 문자열 내에서 중괄호 {}는 변수를 나타냅니다.\\n\\n\\ninput_variables: 중괄호 안에 들어갈 변수의 이름을 리스트로 정의합니다.\\n\\n\\n\\n\\ninput_variables\\n\\n\\ninput_variables는 PromptTemplate에서 사용되는 변수의 이름을 정의하는 리스트입니다.\\n\\n\\n사용법: 리스트 형식으로 변수 이름을 정의합니다.\\n\\n\\n```\\nfrom langchain.prompts import PromptTemplate\\nfrom langchain.chains import LLMChain\\n질문 템플릿 형식 정의\\ntemplate = '{country}의 수도는 뭐야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['country'])\\n```\\nLLMChain 객체\\nLLMChain\\n\\n\\nLLMChain은 특정 PromptTemplate와 연결된 체인 객체를 생성합니다\\n\\n\\n사용법\\n\\n\\nprompt: 앞서 정의한 PromptTemplate 객체를 사용합니다.\\n\\n\\nllm: 언어 모델을 나타내며, 이 예시에서는 이미 어딘가에서 정의된 것으로 보입니다.\\n\\n\\n\\n\\n```\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n① run()\\nrun() 함수로 템플릿 프롬프트 실행\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='일본'))\\n```\\n일본의 수도는 도쿄입니다.\\n```\\n체인 실행: run()\\nprint(llm_chain.run(country='캐나다'))\\n```\\n캐나다의 수도는 오타와(Ottawa)입니다.\\n② apply()\\napply() 함수로 여러개의 입력을 한 번에 실행\\n```\\ninput_list = [\\n    {'country': '호주'},\\n    {'country': '중국'},\\n    {'country': '네덜란드'}\\n]\\nllm_chain.apply(input_list)\\n```\\n[{'text': '호주의 수도는 캔버라입니다.'},\\n {'text': '중국의 수도는 베이징(北京)입니다.'},\\n {'text': '네덜란드의 수도는 암스테르담(Amsterdam)입니다.'}]\\ntext 키 값으로 결과 뭉치가 반환되었음을 확인할 수 있습니다.\\n이를 반복문으로 출력한다면 다음과 같습니다.\\n```\\ninput_list 에 대한 결과 반환\\nresult = llm_chain.apply(input_list)\\n반복문으로 결과 출력\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n③ generate()\\ngenerate() 는 문자열 대신에 LLMResult를 반환하는 점을 제외하고는 apply와 유사합니다.\\nLLMResult는 토큰 사용량과 종료 이유와 같은 유용한 생성 정보를 자주 포함하고 있습니다.\\n```\\ninput_list 에 대한 결과 반환\\ngenerated_result = llm_chain.generate(input_list)\\nprint(generated_result)\\n```\\ngenerations=[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))], [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]] llm_output={'token_usage': {'prompt_tokens': 58, 'completion_tokens': 57, 'total_tokens': 115}, 'model_name': 'gpt-3.5-turbo'} run=[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')), RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')), RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\ngenerated_result.generations\\n```\\n[[ChatGeneration(text='호주의 수도는 캔버라입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='호주의 수도는 캔버라입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='중국의 수도는 베이징(北京)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='중국의 수도는 베이징(北京)입니다.', additional_kwargs={}, example=False))],\\n [ChatGeneration(text='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', generation_info={'finish_reason': 'stop'}, message=AIMessage(content='네덜란드의 수도는 암스테르담(Amsterdam)입니다.', additional_kwargs={}, example=False))]]\\n```\\n토큰 사용량 출력\\ngenerated_result.llm_output\\n```\\n{'token_usage': {'prompt_tokens': 58,\\n  'completion_tokens': 57,\\n  'total_tokens': 115},\\n 'model_name': 'gpt-3.5-turbo'}\\n```\\nrun ID 출력\\ngenerated_result.run\\n```\\n[RunInfo(run_id=UUID('957a5369-a20e-470a-bcea-c325b3aafb4a')),\\n RunInfo(run_id=UUID('f5f6f639-76f8-43e3-9103-03aa7eac6fe5')),\\n RunInfo(run_id=UUID('f9c4ce3f-4e5d-47d5-86af-f20c077b754e'))]\\n```\\n답변 출력\\nfor gen in generated_result.generations:\\n    print(gen[0].text.strip())\\n```\\n호주의 수도는 캔버라입니다.\\n중국의 수도는 베이징(北京)입니다.\\n네덜란드의 수도는 암스테르담(Amsterdam)입니다.\\n④ 2개 이상의 변수를 템플릿 안에 정의\\n2개 이상의 변수를 적용하여 템플릿을 생성할 수 있습니다.\\n이번에는 2개 이상의 변수(input_variables) 를 활용하여 템플릿 구성을 해보겠습니다.\\n```\\n질문 템플릿 형식 정의\\ntemplate = '{area1} 와 {area2} 의 시차는 몇시간이야?'\\n템플릿 완성\\nprompt = PromptTemplate(template=template, input_variables=['area1', 'area2'])\\n연결된 체인(Chain)객체 생성\\nllm_chain = LLMChain(prompt=prompt, llm=llm)\\n```\\n```\\n체인 실행: run()\\nprint(llm_chain.run(area1='서울', area2='파리'))\\n```\\n서울과 파리의 시차는 8시간입니다. 서울이 파리보다 8시간 앞서 있습니다.\\n```\\ninput_list = [\\n    {'area1': '파리', 'area2': '뉴욕'},\\n    {'area1': '서울', 'area2': '하와이'},\\n    {'area1': '켄버라', 'area2': '베이징'}\\n]\\n반복문으로 결과 출력\\nresult = llm_chain.apply(input_list)\\nfor res in result:\\n    print(res['text'].strip())\\n```\\n파리와 뉴욕의 시차는 일반적으로 6시간입니다. 파리가 뉴욕보다 6시간 앞서 있습니다. 예를 들어, 파리가 오전 9시라면 뉴욕은 오전 3시입니다.\\n서울과 하와이의 시차는 서울이 하와이보다 19시간 빠릅니다. 예를 들어, 서울이 오전 9시라면 하와이는 전날 오후 2시입니다.\\n켄버라와 베이징의 시차는 2시간입니다. 켄버라는 오스트레일리아의 수도로 UTC+10 시간대에 위치하고, 베이징은 중국의 수도로 UTC+8 시간대에 위치합니다.\\n⑤ 스트리밍(streaming)\\n스트리밍 옵션은 질의에 대한 답변을 실시간으로 받을 때 유용합니다.\\n다음과 같이 streaming=True 로 설정하고 스트리밍으로 답변을 받기 위한 StreamingStdOutCallbackHandler() 을 콜백으로 지정합니다.\\n```\\nfrom langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\\n객체 생성\\nllm = ChatOpenAI(temperature=0,               # 창의성 (0.0 ~ 2.0) \\n                 max_tokens=2048,             # 최대 토큰수\\n                 model_name='gpt-3.5-turbo',  # 모델명\\n                 streaming=True,            \\n                 callbacks=[StreamingStdOutCallbackHandler()]\\n                )\\n```\\n```\\n질의내용\\nquestion = '대한민국의 수도는 뭐야?'\\n스트리밍으로 답변 출력\\nresponse = llm.predict(question)\\n```\\n대한민국의 수도는 서울입니다.\\n태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, 랭체인, 랭체인 튜토리얼\\n카테고리: langchain\\n업데이트: 2023년 09월 28일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.\"}, {'title': '랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) - 테디노트', 'url': 'https://teddylee777.github.io/langchain/langchain-tutorial-08/', 'content': '랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) - 테디노트 Langchain  랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) ④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌 랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) 이번 포스팅에서는 랭체인(LangChain) 을 활용하여 PDF 문서를 로드하고, 문서의 내용에 기반하여 질의응답(Question-Answering) 하는 방법에 대해 알아보겠습니다. 이번 튜토리얼에서는 langchain 의 문서 로드 - 분할 - 벡터스토어(vectorstore)에 임베딩된 문서를 저장 하는 방법을 다룹니다. 랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법 랭체인(langchain) + PDF 문서요약, Map-Reduce from langchain.document_loaders import PyPDFLoader from langchain.text_splitter import CharacterTextSplitter from langchain.embeddings.openai import OpenAIEmbeddings from langchain.vectorstores import Chroma 아래의 예제는 langchain hub 에서 RAG Prompt 를 가져오는 예제입니다. from langchain import hub from langchain.chat_models import ChatOpenAI 태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, PDF, 랭체인, 랭체인 튜토리얼, 문서요약, 질의응답, 크롤링 카테고리: langchain', 'score': 0.7578844, 'raw_content': '랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8) - 테디노트\\n\\nSkip to primary navigation\\nSkip to content\\nSkip to footer\\n\\n테디노트 데이터와 인공지능을 좋아하는 개발자 노트\\n\\n검색\\n카테고리\\n태그\\n연도\\n강의\\n어바웃미\\n\\n토글 메뉴\\n\\nHome \\n/3.  Langchain \\n/5.  랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8)\\n\\n🔥알림🔥\\n① 테디노트 유튜브 - 구경하러 가기!\\n② LangChain 한국어 튜토리얼 바로가기 👀\\n③ 랭체인 노트 무료 전자책(wikidocs) 바로가기 🙌\\n④ RAG 비법노트 LangChain 강의오픈 바로가기 🙌\\n⑤ 서울대 PyTorch 딥러닝 강의 바로가기 🙌\\n랭체인(langchain) + PDF 기반 질의응답(Question-Answering) (8)\\n2023년 10월 13일 2 분 소요\\n목차\\n\\n🌱 환경설정\\n🔥 PDF 기반 질의 응답(Question-Answering)\\n① 데이터 로드\\n② 데이터 분할\\n③ 저장 및 검색\\n④ 프롬프트 템플릿\\n⑤ 생성\\n⑥ 테스트\\n\\n\\n\\n이번 포스팅에서는 랭체인(LangChain) 을 활용하여 PDF 문서를 로드하고, 문서의 내용에 기반하여 질의응답(Question-Answering) 하는 방법에 대해 알아보겠습니다.\\n이번 튜토리얼에서는 langchain 의 문서 로드 - 분할 - 벡터스토어(vectorstore)에 임베딩된 문서를 저장 하는 방법을 다룹니다. 여러 벡터스토어 중 오픈소스인 Chroma DB 를 활용합니다.\\n후반부에는 langchain hub 에서 프롬프트를 다운로드 받고, 이를 ChatGPT 모델과 결합하여 문서에 기반한 질의응답 Chain 을 생성합니다.\\n\\n✔️ (이전글) LangChain 튜토리얼\\n\\n랭체인(langchain)의 OpenAI GPT 모델(ChatOpenAI) 사용법\\n랭체인(langchain) + 허깅페이스(HuggingFace) 모델 사용법\\n랭체인(langchain) + 챗(chat) - ConversationChain, 템플릿 사용법\\n랭체인(langchain) + 정형데이터(CSV, Excel) - ChatGPT 기반 데이터분석\\n랭체인(langchain) + 웹사이트 크롤링 - 웹사이트 문서 요약\\n랭체인(langchain) + 웹사이트 정보 추출 - 스키마 활용법\\n랭체인(langchain) + PDF 문서요약, Map-Reduce\\n\\n\\n🌱 환경설정\\n```\\n필요한 라이브러리 설치\\n!pip install -q openai langchain langchainhub pypdf\\n```\\n```\\nOPENAI_API\\nimport os\\nos.environ[\\'OPENAI_API_KEY\\'] = \\'OPENAI API KEY 입력\\'\\n```\\n```\\n토큰 정보로드를 위한 라이브러리\\n설치: pip install python-dotenv\\nfrom dotenv import load_dotenv\\n토큰 정보로드\\nload_dotenv()\\n```\\nTrue\\n🔥 PDF 기반 질의 응답(Question-Answering)\\n\\n다음은 비구조화된 데이터를 QA 체인(Question-Answering chain) 으로 변환하는 파이프라인에 대한 기술적 번역입니다:\\n\\n\\n데이터 로드: 우선, 데이터를 로드해야 합니다. LangChain 통합 허브를 사용하여 전체 로더 세트를 둘러보세요.\\n\\n\\n데이터 분할: 텍스트 분할기는 문서를 지정된 크기의 분할로 나눕니다.\\n\\n\\n저장: 저장소(예: 종종 vectorstore)는 분할을 보관하고 종종 임베드합니다.\\n\\n\\n검색: 앱은 저장소에서 분할을 검색합니다(예: 종종 입력 질문과 유사한 임베딩으로).\\n\\n\\n생성: LLM은 질문과 검색된 데이터를 포함하는 프롬프트를 사용하여 답변을 생성합니다.\\n\\n\\n① 데이터 로드\\nPyPDFLoader 를 활용하여 PDF 파일을 로드 합니다.\\n```\\nfrom langchain.document_loaders import PyPDFLoader\\nPDF 파일 로드\\nloader = PyPDFLoader(\"data/황순원-소나기.pdf\")\\ndocument = loader.load()\\ndocument[0].page_content[:200] # 내용 추출\\n```\\n\\'- 1 -소나기\\\\n황순원\\\\n소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀 (曾孫女 )딸이라는 걸 알 수 있었다 . \\\\n소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다 . 서울서는 이런 개울물을 보지 \\\\n못하기나 한 듯이.\\\\n벌써 며칠째 소녀는 , 학교에서 돌아오는 길에 물장난이었다 . 그런데 , 어제까지 개울 기슭에\\\\n서 하더니 , 오늘은 징검다리 한가운\\'\\n② 데이터 분할\\nCharacterTextSplitter 로 chunk_size 기준으로 문서를 쪼갭니다. chunk_overlap 에 50개의 토큰을 지정하여 문서-문서 간 겹쳐지는 부분(overlap) 이 있도록 하여 비교적 유연한 요약 결과를 도출할 수 있도록 합니다.\\n```\\nfrom langchain.text_splitter import CharacterTextSplitter\\ntext_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\\ntexts = text_splitter.split_documents(document)\\n```\\n③ 저장 및 검색\\nOpenAIEmbeddings 를 활용하여 문서의 내용을 임베딩한 뒤, Chroma 벡터스토어(vectorstore) 에 저장합니다.\\n마지막 줄에는 as_retriever() 로 retriever 형태로 가져오는데, 이는 추후 사용자의 query 입력시, 입력된 query로 vectorestore에서 유사성이 높은 데이터를 추출해 낼 때 쓰입니다.\\n```\\nfrom langchain.embeddings.openai import OpenAIEmbeddings\\nfrom langchain.vectorstores import Chroma\\n임베딩\\nembeddings = OpenAIEmbeddings()\\nChroma DB 에 저장\\ndocsearch = Chroma.from_documents(texts, embeddings)\\nretriever 가져옴\\nretriever = docsearch.as_retriever()\\n```\\n④ 프롬프트 템플릿\\n아래의 예제는 langchain hub 에서 RAG Prompt 를 가져오는 예제입니다.\\n이처럼 langchain hub 에서 공개된 프롬프트를 다운로드 받거나, ChatPromptTemplate 를 직접 생성하는 것도 가능합니다. 자세한 사항은 ConversationChain, 템플릿 사용법 에서 확인할 수 있습니다.\\n```\\nlangchain hub 에서 Prompt 다운로드 예시\\nhttps://smith.langchain.com/hub/rlm/rag-prompt\\nfrom langchain import hub\\nrag_prompt = hub.pull(\"rlm/rag-prompt\")\\nrag_prompt\\n```\\nChatPromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\\'question\\', \\'context\\'], output_parser=None, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don\\'t know the answer, just say that you don\\'t know. Use three sentences maximum and keep the answer concise.\\\\nQuestion: {question} \\\\nContext: {context} \\\\nAnswer:\", template_format=\\'f-string\\', validate_template=True), additional_kwargs={})])\\n⑤ 생성\\n마지막 단계는 LLM 모델을 정의하고 Chain 을 생성하는 단계 입니다.\\n```\\nLLM\\nfrom langchain.chat_models import ChatOpenAI\\nChatGPT 모델 지정\\nllm = ChatOpenAI(model_name=\"gpt-4-0613\", temperature=0)\\n```\\n```\\nRAG chain 생성\\nfrom langchain.schema.runnable import RunnablePassthrough\\npipe operator를 활용한 체인 생성\\nrag_chain = (\\n    {\"context\": retriever, \"question\": RunnablePassthrough()} \\n    | rag_prompt \\n    | llm \\n)\\n```\\n⑥ 테스트\\nrag_chain.invoke(\"이 소설의 제목은 뭐야?\")\\nAIMessage(content=\\'이 소설의 제목은 \"소나기\"입니다.\\', additional_kwargs={}, example=False)\\nrag_chain.invoke(\"이 소설의 저자는 누구야?\")\\nAIMessage(content=\\'이 소설의 저자는 황순원입니다.\\', additional_kwargs={}, example=False)\\n태그: ChatGPT, ChatOpenAI, GPT3.5, GPT4, langchain, langchain tutorial, OpenAI, PDF, 랭체인, 랭체인 튜토리얼, 문서요약, 질의응답, 크롤링\\n카테고리: langchain\\n업데이트: 2023년 10월 13일\\n공유하기\\nTwitter Facebook LinkedIn\\n이전 다음\\n댓글남기기\\n참고\\npoetry 의 거의 모든것 (튜토리얼)\\n2024년 03월 30일 5 분 소요\\nPython 개발에 있어서 poetry는 매우 강력한 도구로, 프로젝트의 의존성 관리와 패키지 배포를 간소화하는 데 큰 도움을 줍니다. 지금부터 poetry 활용 튜토리얼을 살펴 보겠습니다.\\nLangGraph Retrieval Agent를 활용한 동적 문서 검색 및 처리\\n2024년 03월 06일 10 분 소요\\nLangGraph Retrieval Agent는 언어 처리, AI 모델 통합, 데이터베이스 관리, 그래프 기반 데이터 처리 등 다양한 기능을 제공하여 언어 기반 AI 애플리케이션 개발에 필수적인 도구입니다.\\n[Assistants API] Code Interpreter, Retrieval, Functions 활용법\\n2024년 02월 13일 35 분 소요\\nOpenAI의 새로운 Assistants API는 대화와 더불어 강력한 도구 접근성을 제공합니다. 본 튜토리얼은 OpenAI Assistants API를 활용하는 내용을 다룹니다. 특히, Assistant API 가 제공하는 도구인 Code Interpreter, Retrieval...\\n[LangChain] 에이전트(Agent)와 도구(tools)를 활용한 지능형 검색 시스템 구축 가이드\\n2024년 02월 09일 41 분 소요\\n이 글에서는 LangChain 의 Agent 프레임워크를 활용하여 복잡한 검색과 데이터 처리 작업을 수행하는 방법을 소개합니다. LangSmith 를 사용하여 Agent의 추론 단계를 추적합니다. Agent가 활용할 검색 도구(Tavily Search), PDF 기반 검색 리트리버...\\n\\n팔로우:\\nYouTube\\nGitHub\\nInstagram\\n피드\\n\\n© 2024 테디노트. Powered by Jekyll & Minimal Mistakes.'}, {'title': ' - LangChain 한국어 튜토리얼 - WikiDocs', 'url': 'https://wikidocs.net/book/14314', 'content': \"대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m. 출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요? CH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m. 좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 '테디노트의 RAG 비법노트' 강의 등록했습니다 ! 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\", 'score': 0.70531887, 'raw_content': '<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 - WikiDocs\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷 CH01 LangChain 시작하기 01. 설치 영상보고 따라하기 02. OpenAI API 키 발급 및 테스트 03. LangSmith 추적 설정 04. OpenAI API 사용(GPT-4o 멀티모달) 05. LangChain Expression Language(LCEL) 06. LCEL 인터페이스 07. Runnable CH02 프롬프트(Prompt) 01. 프롬프트(Prompt) 02. 퓨샷 프롬프트(FewShotPromptTemplate) 03. LangChain Hub 04. 개인화된 프롬프트(Hub에 업로드) CH03 출력 파서(Output Parsers) 01. Pydantic 출력 파서(PydanticOutputParser) 02. 콤마 구분자 출력 파서(CommaSeparatedListOutputParser) 03. 구조화된 출력 파서(StructuredOuputParser) 04. JSON 출력 파서(JsonOutputParser) 05. 데이터프레임 출력 파서(PandasDataFrameOutputParser) 06. 날짜 형식 출력 파서(DatetimeOutputParser) 07. 열거형 출력 파서(EnumOutputParser) 08. 출력 수정 파서(OutputFixingParser) CH04 모델(Model) 01. 다양한 LLM 모델 활용 02. 캐싱(Cache) 03. 모델 직렬화(Serialization) - 저장 및 불러오기 04. 토큰 사용량 확인 05. 구글 생성 AI(Google Generative AI) 06. 허깅페이스 엔드포인트(HuggingFace Endpoints) 07. 허깅페이스 로컬(HuggingFace Local) 08. 허깅페이스 파이프라인(HuggingFace Pipeline) 09. 올라마(Ollama) 10. GPT4ALL 11. 비디오(Video) 질의 응답 LLM (Gemini) CH05 메모리(Memory) 01. 대화 버퍼 메모리(ConversationBufferMemory) 02. 대화 버퍼 윈도우 메모리(ConversationBufferWindowMemory) 03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) 04. 대화 엔티티 메모리(ConversationEntityMemory) 05. 대화 지식그래프 메모리(ConversationKGMemory) 06. 대화 요약 메모리(ConversationSummaryMemory) 07. 벡터저장소 검색 메모리(VectorStoreRetrieverMemory) 08. LCEL Chain 에 메모리 추가 09. SQLite 에 대화내용 저장 10. RunnableWithMessageHistory에 ChatMessageHistory추가 CH06 문서 로더(Document Loader) 01. 도큐먼트(Document) 의 구조 02. PDF 03. 한글(HWP) 04. CSV 05. Excel 06. Word 07. PowerPoint 08. 웹 문서(WebBaseLoader) 09. 텍스트(TextLoader) 10. JSON 11. Arxiv 12. UpstageLayoutAnalysisLoader 13. LlamaParser CH07 텍스트 분할(Text Splitter) 01. 문자 텍스트 분할(CharacterTextSplitter) 02. 재귀적 문자 텍스트 분할(RecursiveCharacterTextSplitter) 03. 토큰 텍스트 분할(TokenTextSplitter) 04. 시멘틱 청커(SemanticChunker) 05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) 06. 마크다운 헤더 텍스트 분할(MarkdownHeaderTextSplitter) 07. HTML 헤더 텍스트 분할(HTMLHeaderTextSplitter) 08. 재귀적 JSON 분할(RecursiveJsonSplitter) CH08 임베딩(Embedding) 01. OpenAIEmbeddings 02. 캐시 임베딩(CacheBackedEmbeddings) 03. 허깅페이스 임베딩(HuggingFace Embeddings) 04. UpstageEmbeddings 05. OllamaEmbeddings 06. GPT4ALL 임베딩 07. Llama CPP 임베딩 CH09 벡터저장소(VectorStore) 01. Chroma 02. FAISS 03. Pinecone CH10 검색기(Retriever) 01. 벡터스토어 기반 검색기(VectorStore-backed Retriever) 02. 문맥 압축 검색기(ContextualCompressionRetriever) 03. 앙상블 검색기(EnsembleRetriever) 04. 긴 문맥 재정렬(LongContextReorder) 05. 상위 문서 검색기(ParentDocumentRetriever) 06. 다중 쿼리 검색기(MultiQueryRetriever) 07. 다중 벡터저장소 검색기(MultiVectorRetriever) 08. 셀프 쿼리 검색기(SelfQueryRetriever) 09. 시간 가중 벡터저장소 검색기(TimeWeightedVectorStoreRetriever) 10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 11. Convex Combination(CC) 적용된 앙상블 검색기(EnsembleRetriever) CH11 리랭커(Reranker) 01. Cross Encoder Reranker 02. Cohere Reranker 03. Jina Reranker 04. FlashRank Reranker CH12 Retrieval Augmented Generation(RAG) 01. PDF 문서 기반 QA(Question-Answer) 02. 네이버 뉴스기사 QA(Question-Answer) 03. RAG 의 기능별 다양한 모듈 활용기 04. RAPTOR: 긴 문맥 요약(Long Context Summary) 05. 대화내용을 기억하는 RAG 체인 CH13 LangChain Expression Language(LCEL) 01. RunnablePassthrough 02. Runnable 구조(그래프) 검토 03. RunnableLambda 04. LLM 체인 라우팅(RunnableLambda, RunnableBranch) 05. RunnableParallel 06. 동적 속성 지정(configurable_fields, configurable_alternatives) 07. @chain 데코레이터로 Runnable 구성 08. RunnableWithMessageHistory 09. 사용자 정의 제네레이터(generator) 10. Runtime Arguments 바인딩 11. 폴백(fallback) 모델 지정 CH14 체인(Chains) 01. 문서 요약 02. SQL 03. 구조화된 출력 체인(with_structered_output) CH15 평가(Evaluations) 01. 합성 테스트 데이터셋 생성(RAGAS) 02. RAGAS 를 활용한 평가 03. 생성한 평가용 데이터셋 업로드(HuggingFace Dataset) 04. LangSmith 데이터셋 생성 05. LLM-as-Judge 06. 임베딩 기반 평가(embedding_distance) 07. 사용자 정의(Custom) LLM 평가 08. Rouge, BLEU, METEOR, SemScore 기반 휴리스틱 평가 09. 실험(Experiment) 평가 비교 10. 요약(Summary) 방식의 평가 11. Groundedness(할루시네이션) 평가 12. 실험 비교(Pairwise Evaluation) 13. 반복 평가 14. 온라인 평가를 활용한 평가 자동화 CH16 에이전트(Agent) 01. 도구(Tools) 02. 도구 바인딩(Binding Tools) 03. 에이전트(Agent) 04. Claude, Gemini, Ollama, Together.ai 를 활용한 Agent 05. Iteration 기능과 사람 개입(Human-in-the-loop) 06. Agentic RAG 07. CSVExcel 데이터 분석 Agent 08. Toolkits 활용 Agent 09. RAG + Image Generator Agent(보고서 작성) 10. 도구를 활용한 토론 에이전트(Two Agent Debates with Tools) CH17 LangGraph 01. 핵심 기능 01. LangGraph 에 자주 등장하는 Python 문법이해 02. LangGraph를 활용한 챗봇 구축 03. LangGraph를 활용한 Agent 구축 04. Agent 에 메모리(memory) 추가 05. 노드의 단계별 스트리밍 출력 06. Human-in-the-loop(사람의 개입) 07. 중간단계 개입 되돌림을 통한 상태 수정과 Replay 08. 사람(Human)에게 물어보는 노드 추가 09. 메시지 삭제(RemoveMessage) 10. ToolNode 를 사용하여 도구를 호출하는 방법 11. 병렬 노드 실행을 위한 분기 생성 방법 12. 대화 기록 요약을 추가하는 방법 13. 서브그래프 추가 및 사용 방법 14. 서브그래프의 입력과 출력을 변환하는 방법 15. LangGraph 스트리밍 모드의 모든 것 02. 구조 설계 01. 기본 그래프 생성 02. Naive RAG 03. 관련성 체커(Relevance Checker) 모듈 추가 04. 웹 검색 모듈 추가 05. 쿼리 재작성 모듈 추가 06. Agentic RAG 07. Adaptive RAG 03. Use Cases 01. 에이전트 대화 시뮬레이션 (고객 응대 시나리오) 02. 사용자 요구사항 기반 메타 프롬프트 생성 에이전트 03. CRAG(Corrective RAG) 04. Self-RAG 05. 계획 후 실행(Plan-and-Execute) 06. 멀티 에이전트 협업 네트워크(Multi-Agent Collaboration Network) 07. 멀티 에이전트 감독자(Multi-Agent Supervisor) 08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) 09. SQL 데이터베이스와 상호작용하는 에이전트 10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 CH18 기타 정보 01. StreamEvent 타입별 정리\\nPublished with WikiDocs\\n\\n\\n<랭체인LangChain 노트> - Lang…\\n\\n\\n도서 증정 이벤트 !!\\n\\nWikiDocs\\n\\n<랭체인LangChain 노트> - LangChain 한국어 튜토리얼🇰🇷\\n\\nAuthor: 테디노트\\nLast edited by : Jan. 16, 2025, 12:23 a.m.\\nCopyright : \\n2,553 Like; \"추천\")\\n추천은 공유할 수 있는 무료 전자책을 집필하는데 정말 큰 힘이 됩니다. \"추천\" 한 번씩만 부탁 드리겠습니다🙏🙏\\n✅ 랭체인 한국어 튜토리얼 강의\\n패스트캠퍼스 - RAG 비법노트\\n✅ 랭체인 한국어 튜토리얼 코드저장소(GitHub) 📘🖥️\\nhttps://github.com/teddylee777/langchain-kr\\n✅ 유튜브 \"테디노트\" 🎥📚\\nhttps://www.youtube.com/c/@teddynote\\n✅ 데이터 분석 블로그 https://teddylee777.github.io\\n✅ 문의 teddylee777@gmail.com\\nLICENSE\\n인용 및 출처 표기\\n\\n본 저작물을 블로그, 유튜브 등 온라인 매체에 인용하여 게재할 경우, Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 반드시 출처를 명시해야 합니다.\\n\\n상업적 사용에 대한 사전 협의\\n\\n본 저작물(Wikidocs 및 관련 실습 코드 포함)을 강의, 강연 등 상업적 목적으로 활용하고자 하는 경우, 저작권자와의 사전 서면 협의가 필수적으로 요구됩니다. 해당 협의는 teddylee777@gmail.com으로 문의하여 진행하실 수 있습니다.\\n\\n본 저작물은 2024년 테디노트에 의해 작성되었습니다. \\n모든 권리는 저작권자에게 있으며, 본 저작물은 Creative Commons Attribution-NonCommercial-NoDerivs 2.0 Korea 라이선스에 따라 배포됩니다.\\n본 저작물의 무단 전재 및 재배포를 금지하며, 전체 혹은 일부를 인용할 경우 출처를 명확히 밝혀주시기 바랍니다.\\n본 문서는 다른 문서의 내용을 참고하여 작성되었을 수 있습니다. 참고 자료는 본 문서 하단의 출처 목록에서 확인하실 수 있습니다.\\nCopyright (c) 테디노트.\\nReference\\n\\nLangChain Github\\nLangGraph Github\\nLangChain Document\\n\\nRecent Comments (8) Recent Modifications (10) RSS\\n02. 네이버 뉴스기사 QA(Question-Answer) - 김민겸, Feb. 2, 2025, 12:17 p.m.\\n\"bullet points 형식으로 정리\"에서 \"주어진 정보에서 질문에 대한 정보를 찾을 수 없습니다.\" 라고 나오는데 이유를 알려주실 수 있나요? kmk582@naver.com\\n10. 한글 형태소 분석기(Kiwi, Kkma, Okt) + BM25 검색기 - shcheon99@naver.com, Jan. 9, 2025, 12:28 p.m.\\n출력된 결과를 비교했을 때, kiwi tokenizer을 사용한 결과와 kkma, okt 를 사용한 결과가 큰 차이가 없다고 봐도 되는 건가요?\\nCH01 LangChain 시작하기 - NamHyeon, Dec. 8, 2024, 1:17 p.m.\\n좋은 자료를 무료로 공유해 주셔서, 감사한 마음에 \\'테디노트의 RAG 비법노트\\' 강의 등록했습니다 ! 물론 제 현업에 필요한 기술이라서, 강의 또한 기쁜 마음에 신청했구요 ~ 정주행 해서, 창공을 날아가 보겠습니다 ^^\\n06. Word - Paul, Oct. 27, 2024, 5:38 p.m.\\npython-docx도 설치해야 할까요?\\n10. JSON - Paul, Oct. 27, 2024, 5:37 p.m.\\n!pip install jq 부분이 들어가야 할 것 같습니다.\\n02. PDF - Paul, Oct. 27, 2024, 3:29 p.m.\\n<html><head> <meta http-equiv=\"Content-Type\" content=\"text/html\"> </head><body> <span style=\"position:absolute; border: gray 1px solid; left:0px; top:50px; width:612px; height:858px;\"></span> <div style=\"position:absolute; top:50px;\"><a name=\"1\">Page 1</a></div> <div style=\"position:absolute; border 이 부분이 출력 결과가 아니라 코드인 것처럼 표시되어 있네요~\\n12. UpstageLayoutAnalysisLoader - Paul, Oct. 27, 2024, 10:59 a.m.\\n감사히 잘 참고하고 있습니다. 아주 사소한 오기이지만... 11번 Arxiv 다음에 12번이 와야 할 텐데, 원래 넣으시려던 다른 목차가 빠진 것인지 바로 13번이 나왔네요^^\\n03. 모델 직렬화(Serialization) - 저장 및 불러오기 - 동구, Sept. 20, 2024, 12:58 p.m.\\nloads는 뭐에요?\\n10. JSON - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. 대화 토큰 버퍼 메모리(ConversationTokenBufferMemory) - Jan. 16, 2025, 12:23 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 코드 분할(Python, Markdown, JAVA, C++, C#, GO, JS, Latex 등) - Jan. 16, 2025, 12:19 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n04. Self-RAG - Dec. 23, 2024, 3:48 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n10. STORM 개념을 도입한 연구를 위한 멀티 에이전트 - Dec. 23, 2024, 3:16 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n03. CRAG(Corrective RAG) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n05. 계획 후 실행(Plan-and-Execute) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n07. 멀티 에이전트 감독자(Multi-Agent Supervisor) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n08. 계층적 멀티 에이전트 팀(Hierarchical Multi-Agent Teams) - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n09. SQL 데이터베이스와 상호작용하는 에이전트 - Dec. 23, 2024, 3:04 a.m.\\n<style> .custom { background-color: #008d8d; color: white; padding: 0.25em 0.5e…\\n\\nNext : CH01 LangChain 시작하기\\n\\n\\n×\\n책갈피\\n추가 닫기\\n\\n×\\nLeave feedback on this page\\nEmail address to reply to\\nWhat you want to say\\n※ Feedback is delivered to the author by email.\\nClose Send'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "\n",
    "# 검색 도구 생성\n",
    "tool = TavilySearch(max_results=3)\n",
    "\n",
    "# 도구 목록에 추가\n",
    "tools = [tool]\n",
    "\n",
    "# 도구 실행\n",
    "print(tool.invoke(\"테디노트 랭체인 튜토리얼\"))\n",
    "# 생성된 내용은 챗봇이 질문에 답할 수 있도록 사용할 수 있는 페이지 요약입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51b6ca3",
   "metadata": {},
   "source": [
    "\n",
    "이번에는 LLM에 `bind_tools`를 추가하여 **LLM + 도구** 를 구성 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596de72d",
   "metadata": {},
   "source": [
    "1. State 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6166da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# 1. State 정의\n",
    "class State(TypedDict):\n",
    "    # list 타입에 add_messages 적용(list 에 message 추가)\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe9e3c7",
   "metadata": {},
   "source": [
    "LLM 을 정의하고 도구를 바인딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c65ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# LLM 에 도구 바인딩\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0c2841",
   "metadata": {},
   "source": [
    "2. 노드를 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "028d36e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노드 함수 정의\n",
    "def chatbot(state: State):\n",
    "    answer = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # 메시지 목록 반환\n",
    "    return {\"messages\": [answer]}  # 자동으로 add_messages 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c798e0",
   "metadata": {},
   "source": [
    "3. 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e8d16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "\n",
    "# 상태 그래프 초기화\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2269f",
   "metadata": {},
   "source": [
    "4. 노드를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273c28ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x734947463400>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a034ee74",
   "metadata": {},
   "source": [
    "## 도구 노드(Tool Node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b08e3f",
   "metadata": {},
   "source": [
    "지금은 직접 구현하지만, 나중에는 LangGraph의 pre-built 되어있는 [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)를 사용\n",
    "\n",
    "- 도구가 호출될 경우 실제로 실행할 수 있는 함수를 만들어야 한다.\n",
    "- 이를 위해 새로운 노드에 도구를 추가\n",
    "- 가장 최근의 메시지를 확인하고 메시지에 `tool_calls`가 포함되어 있으면 도구를 호출하는 `BasicToolNode`를 구현\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1437765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x734947463400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"Run tools requested in the last AIMessage node\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_list = {tool.name: tool for tool in tools}       # 도구 리스트\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):                  # 메시지가 존재할 경우 가장 최근 메시지 1개 추출\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "\n",
    "        # 도구 호출 결과\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # 도구 호출 후 결과 저장\n",
    "            tool_result = self.tools_list[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            outputs.append(\n",
    "                # 도구 호출 결과를 메시지로 저장\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(\n",
    "                        tool_result, ensure_ascii=False\n",
    "                    ),  # 도구 호출 결과를 문자열로 변환\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\"messages\": outputs}            # 어떤 도구를 사용했는지 그리고 그 결과가 무엇인지 반환 -> llm에게 다시 제공 \n",
    "\n",
    "\n",
    "# 도구 노드 생성\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "\n",
    "# 그래프에 도구 노드 추가\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de52ecda",
   "metadata": {},
   "source": [
    "## 조건부 엣지(Conditional Edge)\n",
    "\n",
    "`conditional_edges` 정의\n",
    "\n",
    "**Edges**는 한 노드에서 다음 노드로 제어 흐름을 라우팅\n",
    "\n",
    "**Conditional edges**는 일반적으로 \"if\" 문을 포함하여 현재 그래프 상태에 따라 다른 노드로 라우팅 한다.\n",
    "\n",
    "이러한 함수는 현재 그래프 `state`를 받아 다음에 호출할 Node 를 나타내는 **문자열 또는 문자열 목록** 을 반환한다.\n",
    "\n",
    "아래에서는 `route_tools`라는 라우터 함수를 정의하여 챗봇의 출력에서 `tool_calls`를 확인하고 있다.\n",
    "\n",
    "이 함수를 `add_conditional_edges`를 호출하여 그래프에 제공하면, `chatbot` 노드가 완료될 때마다 이 함수를 확인하여 다음으로 어디로 갈지 결정한다.\n",
    "\n",
    "조건은 도구 호출이 있으면 `tools`로, 없으면 `END`로 라우팅된다.\n",
    "\n",
    "**참고**\n",
    "\n",
    "- langgraph 에 pre-built 되어 있는 [tools_condition](https://langchain-ai.github.io/langgraph/reference/prebuilt/#tools_condition) 으로 대체할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758bf4f",
   "metadata": {},
   "source": [
    "### `add_conditional_edges`\n",
    "\n",
    "![add_conditional_edges](https://github.com/user-attachments/assets/ee25ce94-95a9-4670-86ec-2474057b0555)\n",
    "\n",
    "`add_conditional_edges` 메서드는 시작 노드에서 여러 대상 노드로의 조건부 엣지를 추가합니다.\n",
    "\n",
    "**매개변수**\n",
    "- `source` (str): 시작 노드. 이 노드를 나갈 때 조건부 엣지가 실행됩니다.\n",
    "- `path` (Union[Callable, Runnable]): 다음 노드를 결정하는 호출 가능한 객체 또는 Runnable. `path_map`을 지정하지 않으면 하나 이상의 노드를 반환해야 합니다. `END`를 반환하면 그래프 실행이 중지됩니다.\n",
    "- `path_map` (Optional[Union[dict[Hashable, str], list[str]]]): 경로와 노드 이름 간의 매핑. 생략하면 `path`가 반환하는 값이 노드 이름이어야 합니다.\n",
    "- `then` (Optional[str]): `path`로 선택된 노드 실행 후 실행할 노드의 이름.\n",
    "\n",
    "**반환값**\n",
    "- Self: 메서드 체이닝을 위해 자기 자신을 반환합니다.\n",
    "### `add_conditional_edges`\n",
    "\n",
    "![add_conditional_edges](./image/langgraph-02.png)\n",
    "\n",
    "`add_conditional_edges` 메서드는 시작 노드에서 여러 대상 노드로의 조건부 엣지를 추가한다.\n",
    "\n",
    "**매개변수**\n",
    "- `source` (str): \n",
    "    + 시작 노드. 이 노드를 나갈 때 조건부 엣지가 실행됩니다.\n",
    "- `path` (Union[Callable, Runnable]): \n",
    "    + 다음 노드를 결정하는 호출 가능한 객체 또는 Runnable. \n",
    "    + `path_map`을 지정하지 않으면 하나 이상의 노드를 반환해야 한다.\n",
    "    + `END`를 반환하면 그래프 실행이 중지된다. \n",
    "- `path_map` (Optional[Union[dict[Hashable, str], list[str]]]): \n",
    "    + 경로와 노드 이름 간의 매핑. \n",
    "    + 생략하면 `path`가 반환하는 값이 노드 이름이어야 한다.\n",
    "- `then` (Optional[str]): \n",
    "    +`path`로 선택된 노드 실행 후 실행할 노드의 이름.\n",
    "\n",
    "**예시**\n",
    "\n",
    "```python\n",
    "# `tools_condition` 함수는 챗봇이 도구 사용을 요청하면 \"tools\"를 반환하고, 직접 응답이 가능한 경우 \"END\"를 반환\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    path_map={\"tools\": \"tools\", END: END},  # route_tools 의 반환값이 \"tools\" 인 경우 \"tools\" 노드로, 그렇지 않으면 END 노드로 라우팅\n",
    ")\n",
    "```\n",
    "\n",
    "**반환값**\n",
    "- Self: 메서드 체이닝을 위해 자기 자신을 반환한다.\n",
    "\n",
    "**주요 기능**\n",
    "1. 조건부 엣지를 그래프에 추가\n",
    "2. `path_map`을 딕셔너리로 변환\n",
    "3. `path` 함수의 반환 타입을 분석하여 자동으로 `path_map` 생성 가능\n",
    "4. 조건부 분기를 그래프에 저장\n",
    "\n",
    "**참고**\n",
    "- 이미 컴파일된 그래프에 엣지를 추가하면 경고 메시지가 출력\n",
    "- `path` 함수의 반환 값에 대한 타입 힌트가 없거나 `path_map`이 제공되지 않으면, 그래프 시각화 시 해당 엣지가 그래프의 모든 노드로 전환될 수 있다고 가정한다.\n",
    "- 동일한 이름의 분기가 이미 존재하는 경우 `ValueError`가 발생한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a964c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END\n",
    "\n",
    "\n",
    "def route_tools(\n",
    "    state: State,\n",
    "):\n",
    "    if messages := state.get(\"messages\", []):\n",
    "        # 가장 최근 AI 메시지 추출\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        # 입력 상태에 메시지가 없는 경우 예외 발생\n",
    "        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n",
    "\n",
    "    # AI 메시지에 도구 호출이 있는 경우 \"tools\" 반환\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        # 도구 호출이 있는 경우 \"tools\" 반환\n",
    "        return \"tools\"\n",
    "    # 도구 호출이 없는 경우 \"END\" 반환\n",
    "    return END\n",
    "\n",
    "\n",
    "# `tools_condition` 함수는 챗봇이 도구 사용을 요청하면 \"tools\"를 반환하고, 직접 응답이 가능한 경우 \"END\"를 반환\n",
    "graph_builder.add_conditional_edges(\n",
    "    source=\"chatbot\",\n",
    "    path=route_tools,\n",
    "    # route_tools 의 반환값이 \"tools\" 인 경우 \"tools\" 노드로, 그렇지 않으면 END 노드로 라우팅\n",
    "    path_map={\"tools\": \"tools\", END: END},\n",
    ")\n",
    "\n",
    "# tools > chatbot\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# START > chatbot\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab199c",
   "metadata": {},
   "source": [
    "**조건부 엣지**가 단일 노드에서 시작해야 합니다.\n",
    "\n",
    "이는 그래프에 \"`chatbot`\" 노드가 실행될 때마다 도구를 호출하면 'tools'로 이동하고, 직접 응답하면 루프를 종료하라는 의미입니다. \n",
    "\n",
    "사전 구축된 `tools_condition`처럼, 함수는 도구 호출이 없을 경우 `END` 문자열을 반환(그래프 종료) 합니다. 그래프가 `END`로 전환되면 더 이상 완료할 작업이 없으며 실행을 중지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4d1118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b736b473",
   "metadata": {},
   "source": [
    "이제 봇에게 훈련 데이터 외의 질문을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31343b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='Physical AI에 대해서 알려줘.' additional_kwargs={} response_metadata={} id='412085ad-9da2-4bbd-b9ef-d2ea2cd6f465'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_cc4VbPro8njzG0liwYtcDvNu', 'function': {'arguments': '{\"query\":\"Physical AI 정의 및 이점\"}', 'name': 'tavily_web_search'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 98, 'total_tokens': 121, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_709714d124', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-0d7fefab-b7f9-4d8d-a0a9-58c9a30a5882-0' tool_calls=[{'name': 'tavily_web_search', 'args': {'query': 'Physical AI 정의 및 이점'}, 'id': 'call_cc4VbPro8njzG0liwYtcDvNu', 'type': 'tool_call'}] usage_metadata={'input_tokens': 98, 'output_tokens': 23, 'total_tokens': 121, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='[{\"title\": \"Physical AI란? 인공지능과 로봇의 새로운 융합\", \"url\": \"https://engineer-daddy.co.kr/entry/Physical-AI란-인공지능과-로봇의-새로운-융합\", \"content\": \"Physical AI의 정의 Physical AI 는 인공지능이 물리적인 기기, 로봇, 또는 스마트 시스템과 결합하여 환경과 상호작용하는 기술을 의미합니다. 기존의 AI는 주로 소프트웨어 기반으로 데이터 분석, 패턴 인식, 자연어 처리 등의 역할을 해왔습니다.\", \"score\": 0.84277284, \"raw_content\": \"공학자 아빠의 배움과 유산\\\\n\\\\nPhysical AI란? 인공지능과 로봇의 새로운 융합\\\\n\\\\n인공지능(AI)이 소프트웨어를 넘어 현실 세계에서 물리적으로 작동하는 시대가 도래했습니다. Physical AI는 단순한 알고리즘이 아니라, 실제 기계와 결합하여 인간과 협력하는 인공지능을 의미합니다. 여러분은 혹시 AI가 단순한 데이터 분석 도구가 아닌, 현실에서 직접 움직이고 반응하는 기술이라고 생각해 보신 적 있으신가요? 오늘은 이 새로운 개념을 깊이 탐구하며, 우리가 맞이할 미래를 살펴보겠습니다.\\\\n\\\\n목차\\\\n\\\\nPhysical AI의 정의\\\\n\\\\nPhysical AI는 인공지능이 물리적인 기기, 로봇, 또는 스마트 시스템과 결합하여 환경과 상호작용하는 기술을 의미합니다. 기존의 AI는 주로 소프트웨어 기반으로 데이터 분석, 패턴 인식, 자연어 처리 등의 역할을 해왔습니다. 하지만 Physical AI는 실제 세계에서 작동하는 로봇과 센서를 활용하여 인간과 협력하고, 자율적으로 움직이며, 복잡한 문제를 해결합니다.\\\\n\\\\n이 개념은 로보틱스, 머신러닝, 자율 시스템 등이 융합된 결과로, 스마트 팩토리, 의료 로봇, 자율 주행 자동차 등 다양한 분야에서 활용되고 있습니다. 단순히 ‘똑똑한 기계’를 넘어, 인간과 자연스럽게 소통하고 직접 작업을 수행할 수 있는 새로운 형태의 AI입니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\nPhysical AI의 주요 활용 분야\\\\n\\\\nPhysical AI는 이미 다양한 산업에서 혁신을 이루고 있습니다. 그중에서도 특히 의료, 제조, 자율 주행, 우주 탐사 등의 분야에서 강력한 영향을 미치고 있습니다.\\\\n\\\\n활용 분야 | 설명\\\\n의료 분야 | AI 기반 수술 로봇, 재활 치료 로봇, 환자 모니터링 시스템을 통해 정밀한 치료 제공\\\\n제조 산업 | 스마트 팩토리에서 로봇과 AI가 협력하여 자동화된 생산과 품질 관리 수행\\\\n자율 주행 | AI 기반 자율 주행 시스템이 차량을 스스로 조작하며 안전한 운행 가능\\\\n우주 탐사 | AI 로봇이 인간이 직접 탐사하기 어려운 환경에서 탐험 및 연구 수행\\\\n앞으로 이러한 기술이 더욱 발전하면서, AI는 단순한 도구가 아니라 인간과 협력하는 능동적인 동반자로 자리 잡을 것입니다.\\\\n\\\\n\\\\n\\\\nPhysical AI를 구성하는 핵심 기술\\\\n\\\\nPhysical AI가 현실에서 작동하려면 다양한 기술이 유기적으로 결합되어야 합니다. 인공지능 알고리즘뿐만 아니라, 로보틱스, 센서 기술, 에너지 효율성 등이 중요한 역할을 합니다.\\\\n\\\\nAI가 환경을 학습하고 스스로 판단할 수 있도록 하는 핵심 기술입니다. 신경망을 활용한 패턴 인식과 강화 학습이 적용됩니다.\\\\n\\\\nPhysical AI가 외부 환경을 인식하고 사물을 분석할 수 있도록 도와줍니다. 자율 주행차, 의료 로봇 등에 필수적인 요소입니다.\\\\n\\\\n인공지능이 물리적으로 작동하려면 로봇의 움직임과 다양한 센서(온도, 압력, 광학 등)가 필요합니다.\\\\n\\\\nAI 로봇이 효율적으로 작동하려면 배터리 사용을 최적화하는 기술이 필수적입니다.\\\\n\\\\n\\\\n\\\\nPhysical AI의 미래\\\\n\\\\n\\\\n\\\\nPhysical AI가 직면한 도전 과제\\\\n\\\\nPhysical AI는 많은 가능성을 가지고 있지만, 아직 해결해야 할 중요한 도전 과제들도 있습니다.\\\\n\\\\n⚠️ 데이터 학습 문제: AI가 현실 세계의 환경을 충분히 이해하기 위해서는 방대한 양의 데이터가 필요합니다. 하지만 물리적 환경에서 데이터를 수집하는 것은 쉽지 않습니다.\\\\n\\\\n⚠️ 안전성 및 윤리 문제: AI 로봇이 사람과 함께 작동할 경우 안전성 문제가 중요합니다. 또한, 윤리적인 사용 여부도 고민해야 합니다.\\\\n\\\\n⚠️ 기술적 비용: Physical AI를 개발하고 유지하는 데 드는 비용이 상당히 높아 상용화까지 시간이 필요합니다.\\\\n\\\\n이러한 문제들을 해결하기 위해 AI 연구자들은 지속적으로 새로운 기술을 개발하고 있으며, 정부와 기업 또한 협력하여 안전한 Physical AI 환경을 조성하고 있습니다.\\\\n\\\\n\\\\n\\\\nFAQ\\\\n\\\\nQ1. Physical AI와 일반적인 AI의 차이는 무엇인가요?\\\\n\\\\nPhysical AI는 단순한 소프트웨어 AI가 아니라 실제 로봇, 센서, 기계와 결합하여 물리적으로 동작하는 인공지능을 의미합니다.\\\\n\\\\nQ2. Physical AI는 어떤 산업에서 가장 많이 사용되나요?\\\\n\\\\n의료, 제조업, 자율 주행, 우주 탐사 등에서 활발히 활용되며, 앞으로 다양한 분야로 확대될 전망입니다.\\\\n\\\\nQ3. Physical AI의 개발을 위해 필요한 주요 기술은 무엇인가요?\\\\n\\\\n머신러닝, 로보틱스, 센서 기술, 컴퓨터 비전, 에너지 관리 시스템 등이 핵심 기술로 사용됩니다.\\\\n\\\\nQ4. Physical AI가 직면한 가장 큰 문제는 무엇인가요?\\\\n\\\\n데이터 학습 문제, 안전성 및 윤리 문제, 높은 기술적 비용 등이 해결해야 할 주요 과제입니다.\\\\n\\\\nQ5. Physical AI가 인간의 일자리를 대체할 가능성이 있나요?\\\\n\\\\n일부 단순 반복 업무는 자동화될 가능성이 있지만, 인간과 협력하는 방식으로 발전할 가능성이 더 큽니다.\\\\n\\\\nQ6. Physical AI의 미래는 어떻게 될까요?\\\\n\\\\n더 정교한 자율 시스템과 인간과의 협업이 강화되면서, 산업 전반에서 활용도가 더욱 높아질 것으로 예상됩니다.\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n마무리\\\\n\\\\nPhysical AI는 단순한 소프트웨어 기반 AI를 넘어, 실제 세계에서 직접 작동하는 인공지능의 새로운 시대를 열고 있습니다. 의료, 제조업, 자율 주행, 우주 탐사 등 다양한 산업에서 혁신적인 변화를 이끌고 있으며, 인간과 협력하는 방향으로 발전하고 있습니다.\\\\n\\\\n물론, 여전히 해결해야 할 기술적, 윤리적 도전 과제가 존재하지만, 지속적인 연구와 기술 발전을 통해 Physical AI는 우리 삶의 필수적인 요소가 될 것입니다.\\\\n\\\\n인공지능 로봇 제어 시스템: 혁신적인 자동화 기술\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n\\'Learn > 과학공학기술\\' 카테고리의 다른 글\\\\n\\\\n스테이블 코인 종류: 안정적인 가상 화폐 가이드(0) | 2025.02.22\\\\n크로스체인 브릿지란? 블록체인 간 연결 기술(0) | 2025.02.21\\\\nAI와 블록체인의 만남, 미래 금융 혁신은 어떻게 이뤄질까?(0) | 2025.02.20\\\\n이더리움 2.0: 주요 3가지 변화 및 암호 화폐시장에 미치는 영향(0) | 2025.02.19\\\\n웹3.0이란? 차세대 인터넷 혁명의 모든 것(0) | 2025.02.18\\\\n태그\\\\n\\\\n관련글\\\\n\\\\n공지사항\\\\n\\\\n최근글\\\\n\\\\n인기글\\\\n\\\\n최근댓글\\\\n\\\\n태그\\\\n\\\\n전체 방문자\\\\n\\\\n96,057\\\\n\\\\nToday : 178\\\\n\\\\nYesterday : 268\\\\n\\\\nDesigned by 티스토리\\\\n\\\\n© Kakao Corp.\\\\n\\\\n티스토리툴바\\\\n\\\\n\\\\n\\\\n\"}, {\"title\": \"피지컬(Physical) AI 소개 및 핵심요소, 미래전망\", \"url\": \"https://willskkim.tistory.com/193\", \"content\": \"**피지컬 AI(Physical AI)**는 인공지능(AI)과 로보틱스를 결합한 기술로, AI가 물리적인 환경에서 직접 동작하며 학습하고 적응할 수 있도록 하는 개념입니다.1. 피지컬 AI란?피지컬 AI는 단순히 소프트웨어 기반의 AI 모델을 넘어, 로봇, 자율주행, 스마트 디바이스 등 실제 세계에서 AI가 직접 물리적인\", \"score\": 0.8361405, \"raw_content\": \"티스토리\\\\n\\\\n피지컬(Physical) AI 소개 및 핵심요소, 미래전망\\\\n\\\\n피지컬(Physical) AI 소개 및 핵심요소, 미래전망\\\\n\\\\n출처 : Freepik\\\\n\\\\n\\\\n\\\\n\\\\n\\\\n**피지컬 AI(Physical AI)**는 인공지능(AI)과 로보틱스를 결합한 기술로, AI가 물리적인 환경에서 직접 동작하며 학습하고 적응할 수 있도록 하는 개념입니다.\\\\n\\\\n1. 피지컬 AI란?\\\\n\\\\n피지컬 AI는 단순히 소프트웨어 기반의 AI 모델을 넘어, 로봇, 자율주행, 스마트 디바이스 등 실제 세계에서 AI가 직접 물리적인 작업을 수행할 수 있도록 설계된 기술입니다.이 기술은 머신러닝, 컴퓨터 비전, 센서 기술, 로보틱스 등을 결합하여 자율적인 동작과 의사결정을 가능하게 합니다.\\\\n\\\\n2. 피지컬 AI의 핵심 요소\\\\n\\\\n① 하드웨어 (로봇, 센서, 기계 시스템)\\\\n\\\\n② 소프트웨어 (AI, 머신러닝, 데이터 분석)\\\\n\\\\n3. 피지컬 AI의 활용 분야\\\\n\\\\n① 제조업 & 물류\\\\n\\\\n② 헬스케어 & 재활 로봇\\\\n\\\\n③ 자율주행 & 모빌리티\\\\n\\\\n④ 스마트 홈 & 서비스 로봇\\\\n\\\\n4. 피지컬 AI의 미래 전망\\\\n\\\\n✅ 결론:\\\\n\\\\n피지컬 AI는 AI가 가상 공간이 아닌 실제 세계에서 직접 행동하며, 로봇과 결합해 다양한 산업에서 혁신을 주도하는 기술입니다. 향후 자율 로봇, 스마트 팩토리, 의료 AI, 자율주행 등에서 빠르게 발전할 것으로 기대됩니다.\\\\n\\\\n태그목록\\\\n\\\\n블로그 정보\\\\n\\\\n오늘도 알차게 !  행복하게 !!\\\\n\\\\n티스토리는 카카오에서 사랑을 담아 만듭니다.\\\\n\\\\n\"}, {\"title\": \"피지컬 AI (Physical AI) - anodos.tistory.com\", \"url\": \"https://anodos.tistory.com/entry/피지컬-AIPhysical-AI\", \"content\": \"피지컬 AI(Physical AI)는 인공지능(AI)을 물리적 시스템에 통합하여 기계가 실제 세계와 직접 상호작용할 수 있도록 하는 기술을 말합니다. 기존의 AI가 주로 가상 환경(예: 챗봇, 추천 시스템)에서 작동하는 반면, 피지컬 AI는 센서, 구동 장치(액추에이터), 고급 알고리즘 등을 활용해 물리적 공간에서\", \"score\": 0.81595254, \"raw_content\": \"진리를 향한 끊없는 혼의 동경\\\\n\\\\n피지컬 AI(Physical AI)\\\\n\\\\n피지컬\\xa0AI(Physical\\xa0AI)는\\xa0인공지능(AI)을\\xa0물리적\\xa0시스템에\\xa0통합하여\\xa0기계가\\xa0실제\\xa0세계와\\xa0직접\\xa0상호작용할\\xa0수\\xa0있도록\\xa0하는\\xa0기술을\\xa0말합니다.\\\\n\\\\n기존의\\xa0AI가\\xa0주로\\xa0가상\\xa0환경(예:\\xa0챗봇,\\xa0추천\\xa0시스템)에서\\xa0작동하는\\xa0반면,\\xa0피지컬\\xa0AI는\\xa0센서,\\xa0구동\\xa0장치(액추에이터),\\xa0고급\\xa0알고리즘\\xa0등을\\xa0활용해\\xa0물리적\\xa0공간에서\\xa0데이터를\\xa0수집하고\\xa0이를\\xa0바탕으로\\xa0행동합니다. \\xa0피지컬 AI의 주요 구성 요소\\\\n\\\\n\\\\n\\\\n1.\\xa0센서(Sensors)\\xa0\\xa0 \\xa0\\xa0\\xa0-\\xa0카메라,\\xa0LiDAR,\\xa0마이크,\\xa0온도\\xa0센서\\xa0등\\xa0환경\\xa0정보를\\xa0수집하는\\xa0장치.\\\\n\\\\n2.\\xa0액추에이터(Actuators)\\xa0\\xa0 \\xa0\\xa0\\xa0-\\xa0로봇\\xa0팔,\\xa0바퀴\\xa0등\\xa0기계가\\xa0물리적으로\\xa0움직이거나\\xa0작업을\\xa0수행하도록\\xa0하는\\xa0장치.\\\\n\\\\n\\\\n\\\\n3.\\xa0AI\\xa0알고리즘\\xa0\\xa0 \\xa0\\xa0\\xa0-\\xa0머신러닝\\xa0및\\xa0딥러닝\\xa0모델을\\xa0이용해\\xa0데이터를\\xa0분석하고\\xa0의사결정을\\xa0내리는\\xa0소프트웨어.\\\\n\\\\n\\\\n\\\\n4.\\xa0임베디드\\xa0시스템(Embedded\\xa0Systems)\\xa0\\xa0 \\xa0\\xa0\\xa0-\\xa0기계\\xa0내부에\\xa0내장된\\xa0컴퓨팅\\xa0시스템으로,\\xa0실시간\\xa0데이터\\xa0처리와\\xa0의사결정을\\xa0지원. 피지컬 AI의 작동 방식\\\\n\\\\n피지컬\\xa0AI는\\xa0다음과\\xa0같은\\xa0순환\\xa0과정을\\xa0통해\\xa0작동합니다: 1.\\xa0인식(Perception):\\xa0센서를\\xa0통해\\xa0실시간으로\\xa0환경\\xa0데이터를\\xa0수집. 2.\\xa0처리(Processing):\\xa0AI\\xa0알고리즘이\\xa0데이터를\\xa0분석하고\\xa0패턴이나\\xa0통찰을\\xa0도출. 3.\\xa0의사결정(Decision-Making):\\xa0학습된\\xa0경험과\\xa0예측\\xa0모델을\\xa0바탕으로\\xa0최적의\\xa0행동을\\xa0결정. 4.\\xa0행동(Action):\\xa0액추에이터를\\xa0통해\\xa0작업을\\xa0수행하거나\\xa0환경과\\xa0상호작용. 이\\xa0과정은\\xa0반복되며,\\xa0피지컬\\xa0AI\\xa0시스템은\\xa0변화하는\\xa0환경에\\xa0적응하고\\xa0점점\\xa0더\\xa0효율적으로\\xa0작동할\\xa0수\\xa0있게\\xa0됩니다. \\xa0피지컬 AI의 주요 적용 분야 -\\xa0헬스케어:\\xa0수술\\xa0로봇이\\xa0정밀한\\xa0수술을\\xa0수행하거나\\xa0웨어러블\\xa0기기가\\xa0실시간\\xa0건강\\xa0모니터링. -\\xa0제조업:\\xa0자동화\\xa0로봇이\\xa0조립\\xa0라인에서\\xa0작업\\xa0최적화\\xa0및\\xa0품질\\xa0관리. -\\xa0자율주행\\xa0차량:\\xa0실시간\\xa0환경\\xa0데이터를\\xa0기반으로\\xa0안전하게\\xa0도로를\\xa0주행. -\\xa0스마트\\xa0시티:\\xa0교통\\xa0흐름\\xa0관리,\\xa0공공\\xa0안전\\xa0로봇,\\xa0스마트\\xa0홈\\xa0기기\\xa0등이\\xa0사용자\\xa0행동에\\xa0맞춰\\xa0조정. -\\xa0농업:\\xa0자동화된\\xa0농기계가\\xa0심기,\\xa0물주기,\\xa0수확\\xa0작업을\\xa0최적화. \\xa0피지컬 AI의 특징 -\\xa0실시간\\xa0상호작용:\\xa0센서를\\xa0통해\\xa0즉각적으로\\xa0데이터를\\xa0처리하고\\xa0행동함. -\\xa0적응력:\\xa0과거\\xa0경험을\\xa0학습해\\xa0새로운\\xa0상황에서도\\xa0효과적으로\\xa0대처\\xa0가능. -\\xa0다학문적\\xa0설계:\\xa0로봇공학,\\xa0컴퓨터\\xa0비전,\\xa0기계공학,\\xa0인공지능\\xa0등이\\xa0결합되어\\xa0물리적\\xa0세계와\\xa0원활히\\xa0상호작용. 피지컬 AI의 중요성 피지컬\\xa0AI는\\xa0디지털\\xa0지능과\\xa0실제\\xa0행동\\xa0간의\\xa0격차를\\xa0메우는\\xa0기술로,\\xa0복잡한\\xa0작업을\\xa0자동화하고\\xa0효율성을\\xa0높이며\\xa0오류를\\xa0줄이고\\xa0인간과\\xa0기계\\xa0간\\xa0협력을\\xa0안전하게\\xa0만듭니다.\\xa05G,\\xa0엣지\\xa0컴퓨팅,\\xa0신소재\\xa0과학\\xa0등의\\xa0기술\\xa0발전과\\xa0함께\\xa0피지컬\\xa0AI는\\xa0앞으로\\xa0다양한\\xa0산업에서\\xa0혁신적인\\xa0변화를\\xa0이끌어갈\\xa0것으로\\xa0기대됩니다.\\\\n\\\\n\\'IT•시사•이슈•컬럼 •소식\\' 카테고리의 다른 글\\\\n\\\\n스타벅스 로고속의 여인(0) | 2025.02.02\\\\n\\ufeff딥시크(DeepSeek) 보안 사고(0) | 2025.01.31\\\\n코스모스 플랫폼(0) | 2025.01.31\\\\n트럼프 취임 첫 날 행정명령 서명 계획(0) | 2025.01.18\\\\n탄핵관련 헌법재판소 재판관 임명 현황(0) | 2025.01.03\\\\n티스토리툴바\\\\n\\\\n\\\\n\\\\n\"}]' name='tavily_web_search' id='1c2e8185-27ee-4d82-ba7d-357a1ffd9dfb' tool_call_id='call_cc4VbPro8njzG0liwYtcDvNu'\n",
      "\n",
      "==============\n",
      "STEP: messages\n",
      "==============\n",
      "\n",
      "content='Physical AI(피지컬 AI)는 인공지능(AI)과 로봇 기술이 결합된 새로운 개념으로, AI가 물리적인 환경에서 직접 작동하고 상호작용할 수 있는 기술을 의미합니다. 이는 단순한 소프트웨어 기반 AI를 넘어 실제 로봇, 자율주행 시스템, 스마트 디바이스 등이 환경과 상호작용하며 동작하도록 설계되어 있습니다.\\n\\n### Physical AI의 정의 및 특징\\n- **정의**: Physical AI는 AI가 센서와 기계적 장치를 활용하여 실제 세계에서 데이터를 수집하고 이를 바탕으로 행동하도록 하는 기술입니다. 즉, AI가 물리적 세계와 직접 상호작용할 수 있도록 하는 것입니다.\\n- **주요 특징**:\\n  - **실시간 상호작용**: 환경 데이터를 즉시 처리하여 즉각적인 반응이 가능합니다.\\n  - **적응력**: 과거의 경험을 학습하여 새로운 상황에 효과적으로 대응할 수 있습니다.\\n  - **다학문적 설계**: 로봇 공학, 컴퓨터 비전, 머신러닝 등이 결합되어 작동합니다.\\n\\n### 활용 분야\\nPhysical AI는 다양한 분야에서 응용되고 있습니다.\\n- **의료**: AI 기반의 수술 로봇을 통해 정밀한 수술을 수행하거나, 재활 치료 로봇이 환자의 동작을 지원하는 데 사용됩니다.\\n- **제조업**: 스마트 팩토리에서 자동화 로봇이 생산을 원활하게 하고 품질 관리를 수행합니다.\\n- **자율주행 자동차**: AI가 환경 데이터를 기반으로 차량의 주행을 안전하게 제어합니다.\\n- **서비스 로봇**: 스마트 홈 기기나 공공 안전 로봇이 사용자 요구에 맞춰 조정됩니다.\\n\\n### 미래 전망\\nPhysical AI는 앞으로도 계속 발전할 것으로 기대되며, 자율 시스템, 스마트 팩토리, 의료 등 다양한 산업에서 혁신적인 변화를 이끌어갈 것이 분명합니다. 그러나 데이터 학습, 안전성, 기술적 비용과 같은 몇 가지 도전 과제들도 해결해야 할 부분이 있습니다.\\n\\n이와 관련된 더 자세한 정보를 얻고 싶다면 [여기](https://engineer-daddy.co.kr/entry/Physical-AI란-인공지능과-로봇의-새로운-융합)와 [여기](https://willskkim.tistory.com/193)에서 확인할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 541, 'prompt_tokens': 4064, 'total_tokens': 4605, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_709714d124', 'finish_reason': 'stop', 'logprobs': None} id='run-6368b9f4-fc33-4235-8604-4d677edc9943-0' usage_metadata={'input_tokens': 4064, 'output_tokens': 541, 'total_tokens': 4605, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "inputs = {\"messages\": \"Physical AI에 대해서 알려줘.\"}\n",
    "\n",
    "for event in graph.stream(inputs, stream_mode=\"values\"):\n",
    "    for key, value in event.items():\n",
    "        print(f\"\\n==============\\nSTEP: {key}\\n==============\\n\")\n",
    "        # display_message_tree(value[\"messages\"][-1])\n",
    "        print(value[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6c5ac",
   "metadata": {},
   "source": [
    "도구 호출 후 구조에 대한 이미지\n",
    "\n",
    "![Image](https://github.com/user-attachments/assets/636bfe30-e5e5-4a0c-a6b8-da2c720db522)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23623eec",
   "metadata": {},
   "source": [
    "![](./image/tool-message-01.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
